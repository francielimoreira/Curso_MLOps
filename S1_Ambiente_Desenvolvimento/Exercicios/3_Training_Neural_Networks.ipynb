{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de Redes Neurais\n",
    "\n",
    "A rede que construímos na parte anterior não é tão inteligente, não sabe nada sobre os nossos dígitos manuscritos. Redes neurais com ativações não lineares funcionam como aproximadores de funções universais. Existe alguma função que mapeia sua entrada para a saída. Por exemplo, imagens de dígitos manuscritos para classificar probabilidades. O poder das redes neurais é que podemos treiná-las para aproximar essa função e, basicamente, qualquer função com dados e tempo de computação suficientes.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" largura=500px>\n",
    "\n",
    "A princípio a rede é ingênua, não conhece a função que mapeia as entradas para as saídas. Treinamos a rede mostrando exemplos de dados reais e, em seguida, ajustando os parâmetros da rede de forma que se aproxime desta função.\n",
    "\n",
    "Para encontrar esses parâmetros, precisamos saber quão mal a rede está prevendo os resultados reais. Para isso calculamos uma **função de perda** (também chamada de custo), uma medida do nosso erro de previsão. Por exemplo, a perda quadrática média é frequentemente usada em problemas de regressão e classificação binária\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "onde $n$ é o número de exemplos de treinamento, $y_i$ são os rótulos verdadeiros e $\\hat{y}_i$ são os rótulos previstos.\n",
    "\n",
    "Ao minimizar esta perda em relação aos parâmetros da rede, podemos encontrar configurações onde a perda é mínima e a rede é capaz de prever os rótulos corretos com alta precisão. Encontramos esse mínimo usando um processo chamado **gradiente descendente**. O gradiente é a inclinação da função de perda e aponta na direção da mudança mais rápida. Para chegar ao mínimo no menor tempo, queremos então seguir o gradiente (para baixo). Você pode pensar nisso como descer uma montanha seguindo a encosta mais íngreme até a base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' largura=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Para redes de camada única, a descida gradiente é simples de implementar. No entanto, é mais complicado para redes neurais multicamadas mais profundas como a que construímos. Complicado o suficiente, demorou cerca de 30 anos até que os pesquisadores descobrissem como treinar redes multicamadas.\n",
    "\n",
    "O treinamento de redes multicamadas é feito por meio de **backpropagation**, que na verdade é apenas uma aplicação da regra da cadeia do cálculo. É mais fácil de entender se convertermos uma rede de duas camadas em uma representação gráfica.\n",
    "\n",
    "<img src='assets/backprop_diagram.png' largura=550px>\n",
    "\n",
    "Na passagem direta pela rede, nossos dados e operações vão de baixo para cima aqui. Passamos a entrada $x$ por uma transformação linear $L_1$ com pesos $W_1$ e vieses $b_1$. A saída então passa pela operação sigmóide $S$ e outra transformação linear $L_2$. Finalmente calculamos a perda $\\ell$. Usamos a perda como uma medida de quão ruins são as previsões da rede. O objetivo então é ajustar os pesos e vieses para minimizar a perda.\n",
    "\n",
    "Para treinar os pesos com gradiente descendente, propagamos o gradiente da perda para trás através da rede. Cada operação possui algum gradiente entre as entradas e saídas. À medida que enviamos os gradientes para trás, multiplicamos o gradiente de entrada pelo gradiente da operação. Matematicamente, isso é apenas calcular o gradiente da perda em relação aos pesos usando a regra da cadeia.\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "**Observação:** estou encobrindo alguns detalhes aqui que exigem algum conhecimento de cálculo vetorial, mas eles não são necessários para entender o que está acontecendo.\n",
    "\n",
    "Atualizamos nossos pesos usando este gradiente com alguma taxa de aprendizado $\\alpha$.\n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "A taxa de aprendizagem $\\alpha$ é definida de forma que as etapas de atualização do peso sejam pequenas o suficiente para que o método iterativo se estabeleça no mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses in PyTorch\n",
    "\n",
    "Vamos começar vendo como calculamos a perda com PyTorch. Através do módulo `nn`, PyTorch fornece perdas como a perda de entropia cruzada (`nn.CrossEntropyLoss`). Normalmente você verá a perda atribuída ao `critério`. Conforme observado na última parte, com um problema de classificação como o MNIST, estamos usando a função softmax para prever probabilidades de classe. Com uma saída softmax, você deseja usar entropia cruzada como perda. Para realmente calcular a perda, primeiro você define o critério e depois passa a saída da sua rede e os rótulos corretos.\n",
    "\n",
    "Algo realmente importante a ser observado aqui. Olhando [a documentação para `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> Este critério combina `nn.LogSoftmax()` e `nn.NLLLoss()` em uma única classe.\n",
    ">\n",
    "> Espera-se que a entrada contenha pontuações para cada classe.\n",
    "\n",
    "Isso significa que precisamos passar a saída bruta de nossa rede para a perda, não a saída da função softmax. Essa saída bruta é geralmente chamada de *logits* ou *scores*. Usamos os logits porque o softmax fornece probabilidades que geralmente serão muito próximas de zero ou um, mas os números de ponto flutuante não podem representar com precisão valores próximos de zero ou um ([leia mais aqui](https://docs.python.org /3/tutorial/ponto flutuante.html)). Geralmente é melhor evitar fazer cálculos com probabilidades, normalmente usamos log-probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Se você ainda não viu `nn.Sequential`, por favor termine o final do caderno da Parte 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3235, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na minha experiência, é mais conveniente construir o modelo com uma saída log-softmax usando `nn.LogSoftmax` ou `F.log_softmax` ([documentação](https://pytorch.org/docs/stable/nn.html#torch .nn.LogSoftmax)). Então você pode obter as probabilidades reais tomando o exponencial `torch.exp(output)`. Com uma saída log-softmax, você deseja usar a perda de probabilidade de log negativa, `nn.NLLLoss` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)) .\n",
    "\n",
    ">**Exercício:** Construa um modelo que retorne o log-softmax como saída e calcule a perda usando o log de perda de probabilidade negativa. Observe que para `nn.LogSoftmax` e `F.log_softmax` você precisará definir o argumento da palavra-chave `dim` apropriadamente. `dim = 0` calcula softmax nas linhas, de modo que cada coluna soma 1, enquanto `dim = 1` calcula nas colunas de forma que cada linha soma 1. Pense em como você deseja que a saída seja e escolha `dim` apropriadamente ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (736701735.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    model =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = \n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = \n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3005, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a class for the model\n",
    "class LogSoftmaxModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogSoftmaxModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)  # Apply log-softmax along dimension 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten input tensor\n",
    "        x = self.layers(x)\n",
    "        return self.log_softmax(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = LogSoftmaxModel()\n",
    "\n",
    "# Define the negative log likelihood loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Assuming you have your data loaded in 'images' and 'labels'\n",
    "# Forward pass\n",
    "log_ps = model(images)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(log_ps, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograduação\n",
    "\n",
    "Agora que sabemos como calcular uma perda, como podemos utilizá-la para realizar a retropropagação? O Torch fornece um módulo, `autograd`, para calcular automaticamente os gradientes dos tensores. Podemos usá-lo para calcular os gradientes de todos os nossos parâmetros em relação à perda. O Autograd funciona monitorando as operações realizadas nos tensores e, em seguida, retrocedendo nessas operações, calculando gradientes ao longo do caminho. Para garantir que o PyTorch monitore as operações em um tensor e calcule os gradientes, você precisa definir `requires_grad = True` em um tensor. Você pode fazer isso na criação com a palavra-chave `requires_grad` ou a qualquer momento com `x.requires_grad_(True)`.\n",
    "\n",
    "Você pode desativar gradientes para um bloco de código com o conteúdo `torch.no_grad()`:\n",
    "```píton\n",
    "x = torch.zeros(1, requer_grad=True)\n",
    ">>> com torch.no_grad():\n",
    "... y = x * 2\n",
    ">>> y.requires_grad\n",
    "Falso\n",
    "```\n",
    "\n",
    "Além disso, você pode ativar ou desativar gradientes completamente com `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "Os gradientes são calculados em relação a alguma variável `z` com `z.backward()`. Isso faz uma passagem reversa pelas operações que criaram `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7684,  0.1420],\n",
      "        [-0.9056, -1.2921]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5904, 0.0202],\n",
      "        [0.8201, 1.6694]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver a operação que criou `y`, uma operação de potência `PowBackward0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f298f223280>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn mostra a função que gerou esta variável\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O módulo autograd acompanha essas operações e sabe como calcular o gradiente de cada uma. Desta forma, é possível calcular os gradientes para uma cadeia de operações, em relação a qualquer tensor. Vamos reduzir o tensor `y` a um valor escalar, a média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7750, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode verificar os gradientes de `x` e `y`, mas eles estão vazios no momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular os gradientes, você precisa executar o método `.backward` em uma variável, `z` por exemplo. Isso calculará o gradiente de `z` em relação a `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x }{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3842,  0.0710],\n",
      "        [-0.4528, -0.6460]])\n",
      "tensor([[-0.3842,  0.0710],\n",
      "        [-0.4528, -0.6460]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses cálculos de gradiente são particularmente úteis para redes neurais. Para o treinamento precisamos dos gradientes de custo em relação aos pesos. Com o PyTorch, avançamos os dados pela rede para calcular a perda e, em seguida, retrocedemos para calcular os gradientes em relação à perda. Assim que tivermos os gradientes, podemos dar um passo de descida do gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Autograd together\n",
    "\n",
    "Quando criamos uma rede com PyTorch, todos os parâmetros são inicializados com `requires_grad = True`. Isso significa que quando calculamos a perda e chamamos `loss.backward()`, os gradientes dos parâmetros são calculados. Esses gradientes são usados para atualizar os pesos com a descida do gradiente. Abaixo você pode ver um exemplo de cálculo dos gradientes usando uma passagem para trás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0023, -0.0023, -0.0023,  ..., -0.0023, -0.0023, -0.0023],\n",
      "        [ 0.0013,  0.0013,  0.0013,  ...,  0.0013,  0.0013,  0.0013],\n",
      "        [ 0.0001,  0.0001,  0.0001,  ...,  0.0001,  0.0001,  0.0001],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "Há uma última peça que precisamos para começar a treinar, um otimizador que usaremos para atualizar os pesos com os gradientes. Obtemos isso do [pacote `optim`] do PyTorch (https://pytorch.org/docs/stable/optim.html). Por exemplo, podemos usar descida gradiente estocástica com `optim.SGD`. Você pode ver como definir um otimizador abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sabemos como usar todas as peças individuais, então é hora de ver como elas funcionam juntas. Vamos considerar apenas uma etapa de aprendizado antes de percorrer todos os dados. O processo geral com PyTorch:\n",
    "\n",
    "* Faça uma passagem direta pela rede\n",
    "* Use a saída da rede para calcular a perda\n",
    "* Execute backward pela rede com `loss.backward()` para calcular os gradientes\n",
    "* Dê um passo com o otimizador para atualizar os pesos\n",
    "\n",
    "Abaixo, passarei por uma etapa de treinamento e imprimirei os pesos e gradientes para que você possa ver como isso muda. Observe que tenho uma linha de código `optimizer.zero_grad()`. Quando você faz várias passagens para trás com os mesmos parâmetros, os gradientes são acumulados. Isso significa que você precisa zerar os gradientes em cada passagem de treinamento ou manterá os gradientes dos lotes de treinamento anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0309, -0.0250, -0.0049,  ...,  0.0162, -0.0110,  0.0256],\n",
      "        [ 0.0317,  0.0098,  0.0100,  ...,  0.0314,  0.0233,  0.0213],\n",
      "        [-0.0334,  0.0336, -0.0271,  ..., -0.0072, -0.0180,  0.0341],\n",
      "        ...,\n",
      "        [ 0.0125, -0.0330,  0.0037,  ...,  0.0048,  0.0273, -0.0253],\n",
      "        [ 0.0209,  0.0188,  0.0148,  ...,  0.0182, -0.0107, -0.0125],\n",
      "        [-0.0306, -0.0305, -0.0243,  ..., -0.0255,  0.0081,  0.0094]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-4.4076e-04, -4.4076e-04, -4.4076e-04,  ..., -4.4076e-04,\n",
      "         -4.4076e-04, -4.4076e-04],\n",
      "        [ 1.1082e-03,  1.1082e-03,  1.1082e-03,  ...,  1.1082e-03,\n",
      "          1.1082e-03,  1.1082e-03],\n",
      "        [ 8.9868e-05,  8.9868e-05,  8.9868e-05,  ...,  8.9868e-05,\n",
      "          8.9868e-05,  8.9868e-05],\n",
      "        ...,\n",
      "        [-1.0804e-03, -1.0804e-03, -1.0804e-03,  ..., -1.0804e-03,\n",
      "         -1.0804e-03, -1.0804e-03],\n",
      "        [-3.1452e-03, -3.1452e-03, -3.1452e-03,  ..., -3.1452e-03,\n",
      "         -3.1452e-03, -3.1452e-03],\n",
      "        [ 1.2526e-03,  1.2526e-03,  1.2526e-03,  ...,  1.2526e-03,\n",
      "          1.2526e-03,  1.2526e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0035, -0.0073, -0.0062,  ...,  0.0228,  0.0028, -0.0214],\n",
      "        [-0.0122,  0.0057, -0.0071,  ..., -0.0234,  0.0100,  0.0142],\n",
      "        [ 0.0091, -0.0177, -0.0181,  ...,  0.0266, -0.0095,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0356,  0.0055, -0.0240,  ...,  0.0264,  0.0262,  0.0013],\n",
      "        [-0.0355, -0.0325,  0.0152,  ..., -0.0236, -0.0330,  0.0267],\n",
      "        [-0.0206,  0.0212,  0.0356,  ..., -0.0267,  0.0333,  0.0349]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "Agora colocaremos esse algoritmo em um loop para que possamos percorrer todas as imagens. Em alguma nomenclatura, uma passagem por todo o conjunto de dados é chamada de *época*. Então aqui vamos percorrer o `trainloader` para obter nossos lotes de treinamento. Para cada lote, faremos uma passagem de treinamento onde calculamos a perda, fazemos uma passagem para trás e atualizamos os pesos.\n",
    "\n",
    ">**Exercício:** Implemente o passe de treinamento para nossa rede. Se você implementou corretamente, deverá ver a perda de treinamento cair a cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9269187341112572\n",
      "Training loss: 0.8646754729531722\n",
      "Training loss: 0.5306342620331087\n",
      "Training loss: 0.43102499194490884\n",
      "Training loss: 0.38605478620414796\n"
     ]
    }
   ],
   "source": [
    "## Your solution here\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        \n",
    "        #calculate the loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a rede treinada, podemos verificar suas previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nossa rede é (quase) brilhante (treinamos e “testamos” nos mesmos dados). Ele pode prever com precisão os dígitos em nossas imagens. A seguir, você escreverá o código para treinar uma rede neural em um conjunto de dados mais complexo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
