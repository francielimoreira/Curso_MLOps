{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Validation\n",
    "\n",
    "Agora que você tem uma rede treinada, pode usá-la para fazer previsões. Isso normalmente é chamado de **inferência**, um termo emprestado das estatísticas. No entanto, as redes neurais tendem a ter um desempenho *muito bom* nos dados de treinamento e não são capazes de generalizar para dados que não foram vistos antes. Isso é chamado de **overfitting** e prejudica o desempenho da inferência. Para testar o overfitting durante o treinamento, medimos o desempenho em dados que não estão no conjunto de treinamento chamado conjunto de **validação**. Evitamos overfitting por meio de regularização, como abandono, enquanto monitoramos o desempenho da validação durante o treinamento. Neste notebook, mostrarei como fazer isso no PyTorch.\n",
    "\n",
    "Como sempre, vamos começar carregando o conjunto de dados por meio do torchvision. Você aprenderá mais sobre o torchvision e o carregamento de dados posteriormente. Desta vez aproveitaremos o conjunto de testes que você pode obter definindo `train=False` aqui:\n",
    "\n",
    "```píton\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "O conjunto de teste contém imagens exatamente como o conjunto de treinamento. Normalmente, você verá de 10 a 20% do conjunto de dados original mantido para teste e validação, com o restante sendo usado para treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vou criar um modelo normal, usando o mesmo da minha solução para a parte 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo da validação é medir o desempenho do modelo em dados que não fazem parte do conjunto de treinamento. O desempenho aqui cabe ao desenvolvedor definir. Normalmente, isso é apenas precisão, a porcentagem de classes que a rede previu corretamente. Outras opções são [precisão e recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) e taxa de erro dos 5 principais. Vamos nos concentrar na precisão aqui. Primeiro, farei uma passagem direta com um lote do conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(images))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as probabilidades, podemos obter a classe mais provável usando o método `ps.topk`. Isso retorna os valores mais altos de $k$. Como queremos apenas a classe mais provável, podemos usar `ps.topk(1)`. Isso retorna uma tupla dos principais valores $k$ e dos principais índices $k$. Se o valor mais alto for o quinto elemento, receberemos 4 como índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Look at the most likely classes for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos verificar se as classes previstas correspondem aos rótulos. Isso é simples de fazer igualando `top_class` e `labels`, mas temos que ter cuidado com as formas. Aqui `top_class` é um tensor 2D com forma `(64, 1)` enquanto `labels` é 1D com forma `(64)`. Para que a igualdade funcione da maneira que desejamos, `top_class` e `labels` devem ter o mesmo formato.\n",
    "\n",
    "Se nós fizermos\n",
    "\n",
    "```píton\n",
    "equals = top_class == labels\n",
    "```\n",
    "\n",
    "`equals` terá a forma `(64, 64)`, experimente você mesmo. O que ele está fazendo é comparar o único elemento em cada linha de `top_class` com cada elemento em `labels`, que retorna 64 valores booleanos Verdadeiro/Falso para cada linha. Para evitar isso, usamos o método `.view` em `labels` para transformá-lo no mesmo formato de `top_class`. (O `*top_class.shape` descompacta os valores da forma, então neste caso é o mesmo que escrever `labels.view(64, 1)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos calcular a porcentagem de previsões corretas. `equals` tem valores binários, 0 ou 1. Isso significa que se apenas somarmos todos os valores e dividirmos pelo número de valores, obteremos a porcentagem de previsões corretas. Esta é a mesma operação que calcular a média, então podemos obter a precisão com uma chamada para `torch.mean`. Se fosse assim tão simples. Se você tentar `torch.mean(equals)`, receberá um erro\n",
    "\n",
    "```\n",
    "RuntimeError: a média não está implementada para o tipo torch.ByteTensor\n",
    "```\n",
    "\n",
    "Isso acontece porque `equals` tem o tipo `torch.ByteTensor` mas `torch.mean` não está implementado para tensores com esse tipo. Portanto, precisaremos converter `equals` em um tensor flutuante. Observe que quando pegamos `torch.mean` ele retorna um tensor escalar, para obter o valor real como um float, precisaremos fazer `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.9375%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede não está treinada, então está fazendo suposições aleatórias e devemos ver uma precisão em torno de 10%. Agora vamos treinar nossa rede e incluir nossa passagem de validação para que possamos medir o desempenho da rede no conjunto de teste. Como não estamos atualizando nossos parâmetros na passagem de validação, podemos acelerar nosso código desativando gradientes usando `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```\n",
    ">**Exercício:** Implemente o loop de validação abaixo e imprima a precisão total após o loop. Em grande parte, você pode copiar e colar o código acima, mas sugiro digitá-lo porque escrevê-lo você mesmo é essencial para desenvolver a habilidade. Em geral, você sempre aprenderá mais digitando em vez de copiar e colar. Você deve conseguir uma precisão acima de 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        testt_loss = 0\n",
    "        accuray = 0\n",
    "\n",
    "        # Desativa o cálculo de gradientes para a validação, economizando memória e computação\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_losses += criterion(log_ps, labels)\n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "            \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_losses/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_losses/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.517..  Test Loss: 0.474..  Test Accuracy: 0.825\n",
      "Accuracy: 12951.5625%\n",
      "Epoch: 2/5..  Training Loss: 0.393..  Test Loss: 0.511..  Test Accuracy: 0.819\n",
      "Accuracy: 12865.625%\n",
      "Epoch: 3/5..  Training Loss: 0.359..  Test Loss: 0.388..  Test Accuracy: 0.861\n",
      "Accuracy: 13510.9375%\n",
      "Epoch: 4/5..  Training Loss: 0.334..  Test Loss: 0.389..  Test Accuracy: 0.858\n",
      "Accuracy: 13476.5625%\n",
      "Epoch: 5/5..  Training Loss: 0.318..  Test Loss: 0.379..  Test Accuracy: 0.864\n",
      "Accuracy: 13560.9375%\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # Desativa o cálculo de gradientes para a validação, economizando memória e computação\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Se observarmos as perdas de treinamento e validação à medida que treinamos a rede, podemos ver um fenômeno conhecido como overfitting.\n",
    "\n",
    "<img src='assets/overfitting.png' largura=450px>\n",
    "\n",
    "A rede aprende cada vez melhor o conjunto de treinamento, resultando em menores perdas de treinamento. No entanto, começa a ter problemas ao generalizar para dados fora do conjunto de treinamento, levando ao aumento da perda de validação. O objetivo final de qualquer modelo de aprendizagem profunda é fazer previsões sobre novos dados, por isso devemos nos esforçar para obter a menor perda de validação possível. Uma opção é usar a versão do modelo com menor perda de validação, aqui aquela em torno de 8 a 10 épocas de treinamento. Esta estratégia é chamada de *early-stopping*. Na prática, você salvaria o modelo com frequência durante o treinamento e, posteriormente, escolheria o modelo com a menor perda de validação.\n",
    "\n",
    "O método mais comum para reduzir o overfitting (fora da parada antecipada) é o *dropout*, onde descartamos unidades de entrada aleatoriamente. Isto força a rede a compartilhar informações entre pesos, aumentando sua capacidade de generalização para novos dados. Adicionar dropout no PyTorch é simples usando o módulo [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "Durante o treinamento queremos usar o dropout para evitar overfitting, mas durante a inferência queremos usar a rede inteira. Portanto, precisamos desligar o dropout durante a validação, teste e sempre que usarmos a rede para fazer previsões. Para fazer isso, você usa `model.eval()`. Isso define o modelo para o modo de avaliação onde a probabilidade de dropout é 0. Você pode ativar o dropout novamente configurando o modelo para o modo de treinamento com `model.train()`. Em geral, o padrão para o loop de validação será semelhante a este, onde você desativa os gradientes, define o modelo para o modo de avaliação, calcula a perda de validação e a métrica e, em seguida, define o modelo novamente para o modo de treinamento.\n",
    "\n",
    "```python\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# set model back to train mode\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercício:** Adicione dropout ao seu modelo e treine-o novamente no Fashion-MNIST. Veja se você consegue uma menor perda de validação ou maior precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Define your model with dropout added\n",
    "class ClassifierWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.dropout = nn.Dropout(p=0.2)  # Dropout probability of 20%\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # Pass through the first fully connected layer with ReLU activation and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        # Pass through the second fully connected layer with ReLU activation and dropout\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        # Pass through the third fully connected layer with ReLU activation and dropout\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        # Output layer with log softmax activation\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.604..  Test Loss: 0.464..  Test Accuracy: 0.833\n",
      "Accuracy: 13082.8125%\n",
      "Epoch: 2/5..  Training Loss: 0.480..  Test Loss: 0.425..  Test Accuracy: 0.847\n",
      "Accuracy: 13295.3125%\n",
      "Epoch: 3/5..  Training Loss: 0.447..  Test Loss: 0.408..  Test Accuracy: 0.854\n",
      "Accuracy: 13407.8125%\n",
      "Epoch: 4/5..  Training Loss: 0.433..  Test Loss: 0.437..  Test Accuracy: 0.845\n",
      "Accuracy: 13270.3125%\n",
      "Epoch: 5/5..  Training Loss: 0.416..  Test Loss: 0.434..  Test Accuracy: 0.849\n",
      "Accuracy: 13334.375%\n"
     ]
    }
   ],
   "source": [
    "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
    "model = ClassifierWithDropout()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # Desativa o cálculo de gradientes para a validação, economizando memória e computação\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            #coloca o modelo de volta no modo treinamento\n",
    "            model.train()\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Agora que o modelo está treinado, podemos usá-lo para inferência. Já fizemos isso antes, mas agora precisamos lembrar de definir o modelo no modo de inferência com `model.eval()`. Você também deseja desativar a autogradação com o contexto `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import helper module (should be in the repo)\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "#model = ClassifierWithDropout()\n",
    "#model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Próximo!\n",
    "\n",
    "Na próxima parte, mostrarei como salvar seus modelos treinados. Em geral, você não deseja treinar um modelo sempre que precisar. Em vez disso, você treinará uma vez, salvará e carregará o modelo quando quiser treinar mais ou usá-lo para inferência."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
